# Connected-Component-Image-Clustering
This code performs connected component clustering to segment objects in binary images.

# Code Explanation:

The input image is first converted into a numpy array of datatype float and is converted into a grayscale image by taking the dot product between the image and the vector RGB weights vector [0.2989, 0.5870, 0.1140]. The obtained grayscale image is now converted into a binary image by thresholding, i.e, setting a threshold of 240 and converting all the pixels with intensities less than the threshold to 0 and the pixels with intensities greater than the threshold to 255. This was done since the components had intensities close to 255 but less than 255. Thereby obtaining a binary image. The image is padded with padding of size 1 (constant value = 10). This is done in consideration of the boundary pixels.

An empty dictionary is created. We loop through the image and check if the pixel has an intensity of 255 (white). If it is white, then the pixel to its right and the three pixels below (one right below it and two diagonals) it are checked. If the dictionary is empty, key 0 is created, and the coordinates of the new white pixel and the white pixels surrounding it are appended a list in key 0. If the dictionary is not empty, the presence of the coordinates of the new white pixel is checked across all the lists in all the keys, and if it is present in a particular key, then the coordinates of the white pixels surrounding the new white pixel are appended to that key. By surrounding we mean the pixel to the right, right below it, and the two lower diagonal pixels. It is not necessary to check all the 8 surrounding pixels because we are traversing row by row and the previous pixels wouldâ€™ve already been considered. The dictionary key acts as the class label. Now, if the new white pixel is present in more than one keys i.e, it is present in more than one class, then the contents of the corresponding list are added to the first key and the remaining keys are deleted. For example: if the white pixel is found in three keys (i.e, three classes) 1,2&3, then the contents of 2 and 3 are added to the contents of 1 and 2&3 are deleted.

If the pixel is white and it is not found in any of the already existing keys (classes), then a new key is created with the components as the coordinates of the new white pixel and the white pixels surrounding it. The same procedure is followed for all the pixels in the image resulting in a dictionary with the number of keys as the number of components, and the components of the keys are a list of coordinates of all the pixels belonging to each class/component.

Once the coordinates of the components are obtained, each component is set to a random intensity picked from the range (50,200) without replacement for the purpose of visualization. The initial padding is also removed from the image before returning. The total number of components is obtained from the length of the dictionary. The function returns the segmented image and the number of components.
